import{_ as s,o as n,c as a,R as e}from"./chunks/framework.zUbWieqp.js";const m=JSON.parse('{"title":"NGINX Tuning For Best Performance","description":"","frontmatter":{},"headers":[],"relativePath":"guide/Linux/web/nginx/nginx笔记/nginx_优化.md","filePath":"guide/Linux/web/nginx/nginx笔记/nginx_优化.md","lastUpdated":1701684699000}'),l={name:"guide/Linux/web/nginx/nginx笔记/nginx_优化.md"},o=e(`<h1 id="nginx-tuning-for-best-performance" tabindex="-1">NGINX Tuning For Best Performance <a class="header-anchor" href="#nginx-tuning-for-best-performance" aria-label="Permalink to &quot;NGINX Tuning For Best Performance&quot;">​</a></h1><p>For this configuration you can use web server you like, I decided, because I work mostly with it to use nginx.</p><p>Generally, properly configured nginx can handle up to 400K to 500K requests per second (clustered). Most what I saw is 50K to 80K (non-clustered) requests per second and 30% CPU load, of course, this was <code>2 x Intel Xeon</code> with HyperThreading enabled, but it can work without problem on slower machines.</p><p><strong>You must understand that this config is used in a testing environment and not in production, so you will need to find a way to implement most of those features as best possible for your servers.</strong></p><ul><li><a href="https://nginx.org/en/linux_packages.html#stable" target="_blank" rel="noreferrer">Stable version NGINX (deb/rpm)</a></li><li><a href="https://nginx.org/en/linux_packages.html#mainline" target="_blank" rel="noreferrer">Mainline version NGINX (deb/rpm)</a></li></ul><p>First, you will need to install nginx</p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#B392F0;">yum</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">install</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">nginx</span></span>
<span class="line"><span style="color:#B392F0;">apt</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">install</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">nginx</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#6F42C1;">yum</span><span style="color:#24292E;"> </span><span style="color:#032F62;">install</span><span style="color:#24292E;"> </span><span style="color:#032F62;">nginx</span></span>
<span class="line"><span style="color:#6F42C1;">apt</span><span style="color:#24292E;"> </span><span style="color:#032F62;">install</span><span style="color:#24292E;"> </span><span style="color:#032F62;">nginx</span></span></code></pre></div><p>Backup your original configs and you can start reconfigure your configs. You will need to open your <code>nginx.conf</code> at <code>/etc/nginx/nginx.conf</code> with your favorite editor.</p><div class="language-nginx vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">nginx</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#6A737D;"># you must set worker processes based on your CPU cores, nginx does not benefit from setting more than that</span></span>
<span class="line"><span style="color:#F97583;">worker_processes </span><span style="color:#E1E4E8;">auto; </span><span style="color:#6A737D;">#some last versions calculate it automatically</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># number of file descriptors used for nginx</span></span>
<span class="line"><span style="color:#6A737D;"># the limit for the maximum FDs on the server is usually set by the OS.</span></span>
<span class="line"><span style="color:#6A737D;"># if you don&#39;t set FD&#39;s then OS settings will be used which is by default 2000</span></span>
<span class="line"><span style="color:#F97583;">worker_rlimit_nofile </span><span style="color:#E1E4E8;">100000;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># only log critical errors</span></span>
<span class="line"><span style="color:#F97583;">error_log </span><span style="color:#E1E4E8;">/var/log/nginx/error.log</span><span style="color:#79B8FF;"> crit</span><span style="color:#E1E4E8;">;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># provides the configuration file context in which the directives that affect connection processing are specified.</span></span>
<span class="line"><span style="color:#F97583;">events</span><span style="color:#E1E4E8;"> {</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># determines how much clients will be served per worker</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># max clients = worker_connections * worker_processes</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># max clients is also limited by the number of socket connections available on the system (~64k)</span></span>
<span class="line"><span style="color:#E1E4E8;">   </span><span style="color:#F97583;"> worker_connections </span><span style="color:#E1E4E8;">4000;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># optimized to serve many clients with each thread, essential for linux -- for testing environment</span></span>
<span class="line"><span style="color:#E1E4E8;">   </span><span style="color:#F97583;"> use </span><span style="color:#E1E4E8;">epoll;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># accept as many connections as possible, may flood worker connections if set too low -- for testing environment</span></span>
<span class="line"><span style="color:#E1E4E8;">   </span><span style="color:#F97583;"> multi_accept </span><span style="color:#E1E4E8;">on;</span></span>
<span class="line"><span style="color:#E1E4E8;">}</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F97583;">http</span><span style="color:#E1E4E8;"> {</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># cache informations about FDs, frequently accessed files</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># can boost performance, but you need to test those values</span></span>
<span class="line"><span style="color:#E1E4E8;">   </span><span style="color:#F97583;"> open_file_cache </span><span style="color:#E1E4E8;">max=200000 inactive=20s;</span></span>
<span class="line"><span style="color:#E1E4E8;">   </span><span style="color:#F97583;"> open_file_cache_valid </span><span style="color:#E1E4E8;">30s;</span></span>
<span class="line"><span style="color:#E1E4E8;">   </span><span style="color:#F97583;"> open_file_cache_min_uses </span><span style="color:#E1E4E8;">2;</span></span>
<span class="line"><span style="color:#E1E4E8;">   </span><span style="color:#F97583;"> open_file_cache_errors </span><span style="color:#E1E4E8;">on;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># to boost I/O on HDD we can disable access logs</span></span>
<span class="line"><span style="color:#E1E4E8;">   </span><span style="color:#F97583;"> access_log </span><span style="color:#E1E4E8;">off;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># copies data between one FD and other from within the kernel</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># faster than read() + write()</span></span>
<span class="line"><span style="color:#E1E4E8;">   </span><span style="color:#F97583;"> sendfile </span><span style="color:#E1E4E8;">on;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># send headers in one piece, it is better than sending them one by one</span></span>
<span class="line"><span style="color:#E1E4E8;">   </span><span style="color:#F97583;"> tcp_nopush </span><span style="color:#E1E4E8;">on;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># reduce the data that needs to be sent over network -- for testing environment</span></span>
<span class="line"><span style="color:#E1E4E8;">   </span><span style="color:#F97583;"> gzip </span><span style="color:#E1E4E8;">on;</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># gzip_static on;</span></span>
<span class="line"><span style="color:#E1E4E8;">   </span><span style="color:#F97583;"> gzip_min_length </span><span style="color:#E1E4E8;">10240;</span></span>
<span class="line"><span style="color:#E1E4E8;">   </span><span style="color:#F97583;"> gzip_comp_level </span><span style="color:#E1E4E8;">1;</span></span>
<span class="line"><span style="color:#E1E4E8;">   </span><span style="color:#F97583;"> gzip_vary </span><span style="color:#E1E4E8;">on;</span></span>
<span class="line"><span style="color:#E1E4E8;">   </span><span style="color:#F97583;"> gzip_disable </span><span style="color:#E1E4E8;">msie6;</span></span>
<span class="line"><span style="color:#E1E4E8;">   </span><span style="color:#F97583;"> gzip_proxied </span><span style="color:#E1E4E8;">expired no-cache no-store private auth;</span></span>
<span class="line"><span style="color:#E1E4E8;">   </span><span style="color:#F97583;"> gzip_types</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;"># text/html is always compressed by HttpGzipModule</span></span>
<span class="line"><span style="color:#E1E4E8;">        text/css</span></span>
<span class="line"><span style="color:#E1E4E8;">        text/javascript</span></span>
<span class="line"><span style="color:#E1E4E8;">        text/xml</span></span>
<span class="line"><span style="color:#E1E4E8;">        text/plain</span></span>
<span class="line"><span style="color:#E1E4E8;">        text/x-component</span></span>
<span class="line"><span style="color:#E1E4E8;">        application/javascript</span></span>
<span class="line"><span style="color:#E1E4E8;">        application/x-javascript</span></span>
<span class="line"><span style="color:#E1E4E8;">        application/json</span></span>
<span class="line"><span style="color:#E1E4E8;">        application/xml</span></span>
<span class="line"><span style="color:#E1E4E8;">        application/rss+xml</span></span>
<span class="line"><span style="color:#E1E4E8;">        application/atom+xml</span></span>
<span class="line"><span style="color:#E1E4E8;">        font/truetype</span></span>
<span class="line"><span style="color:#E1E4E8;">        font/opentype</span></span>
<span class="line"><span style="color:#E1E4E8;">        application/vnd.ms-fontobject</span></span>
<span class="line"><span style="color:#E1E4E8;">        image/svg+xml;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># allow the server to close connection on non responding client, this will free up memory</span></span>
<span class="line"><span style="color:#E1E4E8;">   </span><span style="color:#F97583;"> reset_timedout_connection </span><span style="color:#E1E4E8;">on;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># request timed out -- default 60</span></span>
<span class="line"><span style="color:#E1E4E8;">   </span><span style="color:#F97583;"> client_body_timeout </span><span style="color:#E1E4E8;">10;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># if client stop responding, free up memory -- default 60</span></span>
<span class="line"><span style="color:#E1E4E8;">   </span><span style="color:#F97583;"> send_timeout </span><span style="color:#E1E4E8;">2;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># server will close connection after this time -- default 75</span></span>
<span class="line"><span style="color:#E1E4E8;">   </span><span style="color:#F97583;"> keepalive_timeout </span><span style="color:#E1E4E8;">30;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># number of requests client can make over keep-alive -- for testing environment</span></span>
<span class="line"><span style="color:#E1E4E8;">   </span><span style="color:#F97583;"> keepalive_requests </span><span style="color:#E1E4E8;">100000;</span></span>
<span class="line"><span style="color:#E1E4E8;">}</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#6A737D;"># you must set worker processes based on your CPU cores, nginx does not benefit from setting more than that</span></span>
<span class="line"><span style="color:#D73A49;">worker_processes </span><span style="color:#24292E;">auto; </span><span style="color:#6A737D;">#some last versions calculate it automatically</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># number of file descriptors used for nginx</span></span>
<span class="line"><span style="color:#6A737D;"># the limit for the maximum FDs on the server is usually set by the OS.</span></span>
<span class="line"><span style="color:#6A737D;"># if you don&#39;t set FD&#39;s then OS settings will be used which is by default 2000</span></span>
<span class="line"><span style="color:#D73A49;">worker_rlimit_nofile </span><span style="color:#24292E;">100000;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># only log critical errors</span></span>
<span class="line"><span style="color:#D73A49;">error_log </span><span style="color:#24292E;">/var/log/nginx/error.log</span><span style="color:#005CC5;"> crit</span><span style="color:#24292E;">;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># provides the configuration file context in which the directives that affect connection processing are specified.</span></span>
<span class="line"><span style="color:#D73A49;">events</span><span style="color:#24292E;"> {</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># determines how much clients will be served per worker</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># max clients = worker_connections * worker_processes</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># max clients is also limited by the number of socket connections available on the system (~64k)</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#D73A49;"> worker_connections </span><span style="color:#24292E;">4000;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># optimized to serve many clients with each thread, essential for linux -- for testing environment</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#D73A49;"> use </span><span style="color:#24292E;">epoll;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># accept as many connections as possible, may flood worker connections if set too low -- for testing environment</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#D73A49;"> multi_accept </span><span style="color:#24292E;">on;</span></span>
<span class="line"><span style="color:#24292E;">}</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">http</span><span style="color:#24292E;"> {</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># cache informations about FDs, frequently accessed files</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># can boost performance, but you need to test those values</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#D73A49;"> open_file_cache </span><span style="color:#24292E;">max=200000 inactive=20s;</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#D73A49;"> open_file_cache_valid </span><span style="color:#24292E;">30s;</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#D73A49;"> open_file_cache_min_uses </span><span style="color:#24292E;">2;</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#D73A49;"> open_file_cache_errors </span><span style="color:#24292E;">on;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># to boost I/O on HDD we can disable access logs</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#D73A49;"> access_log </span><span style="color:#24292E;">off;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># copies data between one FD and other from within the kernel</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># faster than read() + write()</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#D73A49;"> sendfile </span><span style="color:#24292E;">on;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># send headers in one piece, it is better than sending them one by one</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#D73A49;"> tcp_nopush </span><span style="color:#24292E;">on;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># reduce the data that needs to be sent over network -- for testing environment</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#D73A49;"> gzip </span><span style="color:#24292E;">on;</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># gzip_static on;</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#D73A49;"> gzip_min_length </span><span style="color:#24292E;">10240;</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#D73A49;"> gzip_comp_level </span><span style="color:#24292E;">1;</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#D73A49;"> gzip_vary </span><span style="color:#24292E;">on;</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#D73A49;"> gzip_disable </span><span style="color:#24292E;">msie6;</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#D73A49;"> gzip_proxied </span><span style="color:#24292E;">expired no-cache no-store private auth;</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#D73A49;"> gzip_types</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># text/html is always compressed by HttpGzipModule</span></span>
<span class="line"><span style="color:#24292E;">        text/css</span></span>
<span class="line"><span style="color:#24292E;">        text/javascript</span></span>
<span class="line"><span style="color:#24292E;">        text/xml</span></span>
<span class="line"><span style="color:#24292E;">        text/plain</span></span>
<span class="line"><span style="color:#24292E;">        text/x-component</span></span>
<span class="line"><span style="color:#24292E;">        application/javascript</span></span>
<span class="line"><span style="color:#24292E;">        application/x-javascript</span></span>
<span class="line"><span style="color:#24292E;">        application/json</span></span>
<span class="line"><span style="color:#24292E;">        application/xml</span></span>
<span class="line"><span style="color:#24292E;">        application/rss+xml</span></span>
<span class="line"><span style="color:#24292E;">        application/atom+xml</span></span>
<span class="line"><span style="color:#24292E;">        font/truetype</span></span>
<span class="line"><span style="color:#24292E;">        font/opentype</span></span>
<span class="line"><span style="color:#24292E;">        application/vnd.ms-fontobject</span></span>
<span class="line"><span style="color:#24292E;">        image/svg+xml;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># allow the server to close connection on non responding client, this will free up memory</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#D73A49;"> reset_timedout_connection </span><span style="color:#24292E;">on;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># request timed out -- default 60</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#D73A49;"> client_body_timeout </span><span style="color:#24292E;">10;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># if client stop responding, free up memory -- default 60</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#D73A49;"> send_timeout </span><span style="color:#24292E;">2;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># server will close connection after this time -- default 75</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#D73A49;"> keepalive_timeout </span><span style="color:#24292E;">30;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># number of requests client can make over keep-alive -- for testing environment</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#D73A49;"> keepalive_requests </span><span style="color:#24292E;">100000;</span></span>
<span class="line"><span style="color:#24292E;">}</span></span></code></pre></div><p>Now you can save the configuration and run the below <a href="https://www.nginx.com/resources/wiki/start/topics/tutorials/commandline/#stopping-or-restarting-nginx" target="_blank" rel="noreferrer">command</a></p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#e1e4e8;">nginx -s reload</span></span>
<span class="line"><span style="color:#e1e4e8;">/etc/init.d/nginx start|restart</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">nginx -s reload</span></span>
<span class="line"><span style="color:#24292e;">/etc/init.d/nginx start|restart</span></span></code></pre></div><p>If you wish to test the configuration first you can run</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#e1e4e8;">nginx -t</span></span>
<span class="line"><span style="color:#e1e4e8;">/etc/init.d/nginx configtest</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">nginx -t</span></span>
<span class="line"><span style="color:#24292e;">/etc/init.d/nginx configtest</span></span></code></pre></div><h2 id="just-for-security-reasons" tabindex="-1">Just For Security Reasons <a class="header-anchor" href="#just-for-security-reasons" aria-label="Permalink to &quot;Just For Security Reasons&quot;">​</a></h2><div class="language-nginx vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">nginx</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#F97583;">server_tokens </span><span style="color:#E1E4E8;">off;</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#D73A49;">server_tokens </span><span style="color:#24292E;">off;</span></span></code></pre></div><h2 id="nginx-simple-ddos-defense" tabindex="-1">NGINX Simple DDoS Defense <a class="header-anchor" href="#nginx-simple-ddos-defense" aria-label="Permalink to &quot;NGINX Simple DDoS Defense&quot;">​</a></h2><p>This is far away from a secure DDoS defense but can slow down some small DDoS. This configuration is for a testing environment and you should use your own values.</p><div class="language-nginx vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">nginx</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#6A737D;"># limit the number of connections per single IP</span></span>
<span class="line"><span style="color:#F97583;">limit_conn_zone </span><span style="color:#E1E4E8;">$binary_remote_addr zone=conn_limit_per_ip:10m;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># limit the number of requests for a given session</span></span>
<span class="line"><span style="color:#F97583;">limit_req_zone </span><span style="color:#E1E4E8;">$binary_remote_addr zone=req_limit_per_ip:10m rate=5r/s;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># zone which we want to limit by upper values, we want limit whole server</span></span>
<span class="line"><span style="color:#F97583;">server</span><span style="color:#E1E4E8;"> {</span></span>
<span class="line"><span style="color:#E1E4E8;">   </span><span style="color:#F97583;"> limit_conn </span><span style="color:#E1E4E8;">conn_limit_per_ip </span><span style="color:#79B8FF;">10</span><span style="color:#E1E4E8;">;</span></span>
<span class="line"><span style="color:#E1E4E8;">   </span><span style="color:#F97583;"> limit_req </span><span style="color:#E1E4E8;">zone=req_limit_per_ip burst=10 nodelay;</span></span>
<span class="line"><span style="color:#E1E4E8;">}</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># if the request body size is more than the buffer size, then the entire (or partial)</span></span>
<span class="line"><span style="color:#6A737D;"># request body is written into a temporary file</span></span>
<span class="line"><span style="color:#F97583;">client_body_buffer_size </span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">128k</span><span style="color:#E1E4E8;">;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># buffer size for reading client request header -- for testing environment</span></span>
<span class="line"><span style="color:#F97583;">client_header_buffer_size </span><span style="color:#E1E4E8;">3m;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># maximum number and size of buffers for large headers to read from client request</span></span>
<span class="line"><span style="color:#F97583;">large_client_header_buffers </span><span style="color:#E1E4E8;">4 </span><span style="color:#79B8FF;">256k</span><span style="color:#E1E4E8;">;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># read timeout for the request body from client -- for testing environment</span></span>
<span class="line"><span style="color:#F97583;">client_body_timeout </span><span style="color:#E1E4E8;">  </span><span style="color:#79B8FF;">3m</span><span style="color:#E1E4E8;">;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># how long to wait for the client to send a request header -- for testing environment</span></span>
<span class="line"><span style="color:#F97583;">client_header_timeout </span><span style="color:#E1E4E8;">3m;</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#6A737D;"># limit the number of connections per single IP</span></span>
<span class="line"><span style="color:#D73A49;">limit_conn_zone </span><span style="color:#24292E;">$binary_remote_addr zone=conn_limit_per_ip:10m;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># limit the number of requests for a given session</span></span>
<span class="line"><span style="color:#D73A49;">limit_req_zone </span><span style="color:#24292E;">$binary_remote_addr zone=req_limit_per_ip:10m rate=5r/s;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># zone which we want to limit by upper values, we want limit whole server</span></span>
<span class="line"><span style="color:#D73A49;">server</span><span style="color:#24292E;"> {</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#D73A49;"> limit_conn </span><span style="color:#24292E;">conn_limit_per_ip </span><span style="color:#005CC5;">10</span><span style="color:#24292E;">;</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#D73A49;"> limit_req </span><span style="color:#24292E;">zone=req_limit_per_ip burst=10 nodelay;</span></span>
<span class="line"><span style="color:#24292E;">}</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># if the request body size is more than the buffer size, then the entire (or partial)</span></span>
<span class="line"><span style="color:#6A737D;"># request body is written into a temporary file</span></span>
<span class="line"><span style="color:#D73A49;">client_body_buffer_size </span><span style="color:#24292E;"> </span><span style="color:#005CC5;">128k</span><span style="color:#24292E;">;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># buffer size for reading client request header -- for testing environment</span></span>
<span class="line"><span style="color:#D73A49;">client_header_buffer_size </span><span style="color:#24292E;">3m;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># maximum number and size of buffers for large headers to read from client request</span></span>
<span class="line"><span style="color:#D73A49;">large_client_header_buffers </span><span style="color:#24292E;">4 </span><span style="color:#005CC5;">256k</span><span style="color:#24292E;">;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># read timeout for the request body from client -- for testing environment</span></span>
<span class="line"><span style="color:#D73A49;">client_body_timeout </span><span style="color:#24292E;">  </span><span style="color:#005CC5;">3m</span><span style="color:#24292E;">;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># how long to wait for the client to send a request header -- for testing environment</span></span>
<span class="line"><span style="color:#D73A49;">client_header_timeout </span><span style="color:#24292E;">3m;</span></span></code></pre></div><p>Now you can test the configuration again</p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#B392F0;">nginx</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">-t</span><span style="color:#E1E4E8;"> </span><span style="color:#6A737D;"># /etc/init.d/nginx configtest</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#6F42C1;">nginx</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">-t</span><span style="color:#24292E;"> </span><span style="color:#6A737D;"># /etc/init.d/nginx configtest</span></span></code></pre></div><p>And then <a href="https://www.nginx.com/resources/wiki/start/topics/tutorials/commandline/#stopping-or-restarting-nginx" target="_blank" rel="noreferrer">reload or restart your nginx</a></p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#e1e4e8;">nginx -s reload</span></span>
<span class="line"><span style="color:#e1e4e8;">/etc/init.d/nginx reload|restart</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">nginx -s reload</span></span>
<span class="line"><span style="color:#24292e;">/etc/init.d/nginx reload|restart</span></span></code></pre></div><p>You can test this configuration with <code>tsung</code> and when you are satisfied with the result you can hit <code>Ctrl+C</code> because it can run for hours.</p><h2 id="increase-the-maximum-number-of-open-files-nofile-limit-–-linux" tabindex="-1">Increase The Maximum Number Of Open Files (<code>nofile</code> limit) – Linux <a class="header-anchor" href="#increase-the-maximum-number-of-open-files-nofile-limit-–-linux" aria-label="Permalink to &quot;Increase The Maximum Number Of Open Files (\`nofile\` limit) – Linux&quot;">​</a></h2><p>There are two ways to raise the nofile/max open files/file descriptors/file handles limit for NGINX in RHEL/CentOS 7+. With NGINX running, check the current limit on the master process</p><pre><code>$ cat /proc/$(cat /var/run/nginx.pid)/limits | grep open.files
Max open files            1024                 4096                 files
</code></pre><h4 id="and-worker-processes" tabindex="-1">And worker processes <a class="header-anchor" href="#and-worker-processes" aria-label="Permalink to &quot;And worker processes&quot;">​</a></h4><pre><code>ps --ppid $(cat /var/run/nginx.pid) -o %p|sed &#39;1d&#39;|xargs -I{} cat /proc/{}/limits|grep open.files

Max open files            1024                 4096                 files
Max open files            1024                 4096                 files
</code></pre><p>Trying with the <code>worker_rlimit_nofile</code> directive in <code>{,/usr/local}/etc/nginx/nginx.conf</code> fails as SELinux policy doesn&#39;t allow <code>setrlimit</code>. This is shown in <code>/var/log/nginx/error.log</code></p><pre><code>015/07/24 12:46:40 [alert] 12066#0: setrlimit(RLIMIT_NOFILE, 2342) failed (13: Permission denied)
</code></pre><h4 id="and-in-var-log-audit-audit-log" tabindex="-1">And in /var/log/audit/audit.log <a class="header-anchor" href="#and-in-var-log-audit-audit-log" aria-label="Permalink to &quot;And in /var/log/audit/audit.log&quot;">​</a></h4><pre><code>type=AVC msg=audit(1437731200.211:366): avc:  denied  { setrlimit } for  pid=12066 comm=&quot;nginx&quot; scontext=system_u:system_r:httpd_t:s0 tcontext=system_u:system_r:httpd_t:s0 tclass=process
</code></pre><h4 id="nolimit-without-systemd" tabindex="-1"><code>nolimit</code> without Systemd <a class="header-anchor" href="#nolimit-without-systemd" aria-label="Permalink to &quot;\`nolimit\` without Systemd&quot;">​</a></h4><pre><code># /etc/security/limits.conf
# /etc/default/nginx (ULIMIT)
$ nano /etc/security/limits.d/nginx.conf
nginx   soft    nofile  65536
nginx   hard    nofile  65536
$ sysctl -p
</code></pre><h4 id="nolimit-with-systemd" tabindex="-1"><code>nolimit</code> with Systemd <a class="header-anchor" href="#nolimit-with-systemd" aria-label="Permalink to &quot;\`nolimit\` with Systemd&quot;">​</a></h4><pre><code>$ mkdir -p /etc/systemd/system/nginx.service.d
$ nano /etc/systemd/system/nginx.service.d/nginx.conf
[Service]
LimitNOFILE=30000
$ systemctl daemon-reload
$ systemctl restart nginx.service
</code></pre><h4 id="selinux-boolean-httpd-setrlimit-to-true-1" tabindex="-1">SELinux boolean <code>httpd_setrlimit</code> to true(1) <a class="header-anchor" href="#selinux-boolean-httpd-setrlimit-to-true-1" aria-label="Permalink to &quot;SELinux boolean \`httpd_setrlimit\` to true(1)&quot;">​</a></h4><p>This will set fd limits for the worker processes. Leave the <code>worker_rlimit_nofile</code> directive in <code>{,/usr/local}/etc/nginx/nginx.conf</code> and run the following as root</p><pre><code>setsebool -P httpd_setrlimit 1
</code></pre><h2 id="dos-http-1-1-and-above-range-requests" tabindex="-1">DoS <a href="https://tools.ietf.org/html/rfc7233#section-6.1" target="_blank" rel="noreferrer">HTTP/1.1 and above: Range Requests</a> <a class="header-anchor" href="#dos-http-1-1-and-above-range-requests" aria-label="Permalink to &quot;DoS [HTTP/1.1 and above: Range Requests](https://tools.ietf.org/html/rfc7233#section-6.1)&quot;">​</a></h2><p>By default <a href="https://nginx.org/r/max_ranges" target="_blank" rel="noreferrer"><code>max_ranges</code></a> is not limited. DoS attacks can create many Range-Requests (Impact on stability I/O).</p><h2 id="socket-sharding-in-nginx-1-9-1-dragonfly-bsd-and-linux-3-9" tabindex="-1">Socket Sharding in NGINX 1.9.1+ (DragonFly BSD and Linux 3.9+) <a class="header-anchor" href="#socket-sharding-in-nginx-1-9-1-dragonfly-bsd-and-linux-3-9" aria-label="Permalink to &quot;Socket Sharding in NGINX 1.9.1+ (DragonFly BSD and Linux 3.9+)&quot;">​</a></h2><table><thead><tr><th>Socket type</th><th>Latency (ms)</th><th>Latency stdev (ms)</th><th>CPU Load</th></tr></thead><tbody><tr><td>Default</td><td>15.65</td><td>26.59</td><td>0.3</td></tr><tr><td>accept_mutex off</td><td>15.59</td><td>26.48</td><td>10</td></tr><tr><td>reuseport</td><td>12.35</td><td>3.15</td><td>0.3</td></tr></tbody></table><h2 id="thread-pools-in-nginx-boost-performance-9x-linux" tabindex="-1"><a href="https://nginx.org/r/thread_pool" target="_blank" rel="noreferrer">Thread Pools</a> in NGINX Boost Performance 9x! (Linux) <a class="header-anchor" href="#thread-pools-in-nginx-boost-performance-9x-linux" aria-label="Permalink to &quot;[Thread Pools](https://nginx.org/r/thread_pool) in NGINX Boost Performance 9x! (Linux)&quot;">​</a></h2><p><a href="https://nginx.org/r/aio" target="_blank" rel="noreferrer">Multi-threaded</a> sending of files is currently supported only in Linux. Without <a href="https://nginx.org/r/sendfile_max_chunk" target="_blank" rel="noreferrer"><code>sendfile_max_chunk</code></a> limit, one fast connection may seize the worker process entirely.</p><h2 id="selecting-an-upstream-based-on-ssl-protocol-version" tabindex="-1">Selecting an upstream based on SSL protocol version <a class="header-anchor" href="#selecting-an-upstream-based-on-ssl-protocol-version" aria-label="Permalink to &quot;Selecting an upstream based on SSL protocol version&quot;">​</a></h2><div class="language-nginx vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">nginx</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#F97583;">map</span><span style="color:#E1E4E8;"> $</span><span style="color:#FFAB70;">ssl_preread_protocol</span><span style="color:#E1E4E8;"> $upstream {</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#9ECBFF;">&quot;&quot;</span><span style="color:#E1E4E8;">        ssh.example.com:22;</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#9ECBFF;">&quot;TLSv1.2&quot;</span><span style="color:#E1E4E8;"> new.example.com:443;</span></span>
<span class="line"><span style="color:#E1E4E8;">   </span><span style="color:#79B8FF;"> default</span><span style="color:#E1E4E8;">   tls.example.com:443;</span></span>
<span class="line"><span style="color:#E1E4E8;">}</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># ssh and https on the same port</span></span>
<span class="line"><span style="color:#F97583;">server</span><span style="color:#E1E4E8;"> {</span></span>
<span class="line"><span style="color:#E1E4E8;">   </span><span style="color:#F97583;"> listen </span><span style="color:#E1E4E8;">     192.168.0.1:443;</span></span>
<span class="line"><span style="color:#E1E4E8;">   </span><span style="color:#F97583;"> proxy_pass </span><span style="color:#E1E4E8;"> $upstream;</span></span>
<span class="line"><span style="color:#E1E4E8;">   </span><span style="color:#F97583;"> ssl_preread </span><span style="color:#E1E4E8;">on;</span></span>
<span class="line"><span style="color:#E1E4E8;">}</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#D73A49;">map</span><span style="color:#24292E;"> $</span><span style="color:#E36209;">ssl_preread_protocol</span><span style="color:#24292E;"> $upstream {</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#032F62;">&quot;&quot;</span><span style="color:#24292E;">        ssh.example.com:22;</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#032F62;">&quot;TLSv1.2&quot;</span><span style="color:#24292E;"> new.example.com:443;</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#005CC5;"> default</span><span style="color:#24292E;">   tls.example.com:443;</span></span>
<span class="line"><span style="color:#24292E;">}</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># ssh and https on the same port</span></span>
<span class="line"><span style="color:#D73A49;">server</span><span style="color:#24292E;"> {</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#D73A49;"> listen </span><span style="color:#24292E;">     192.168.0.1:443;</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#D73A49;"> proxy_pass </span><span style="color:#24292E;"> $upstream;</span></span>
<span class="line"><span style="color:#24292E;">   </span><span style="color:#D73A49;"> ssl_preread </span><span style="color:#24292E;">on;</span></span>
<span class="line"><span style="color:#24292E;">}</span></span></code></pre></div><h1 id="happy-hacking" tabindex="-1">Happy Hacking! <a class="header-anchor" href="#happy-hacking" aria-label="Permalink to &quot;Happy Hacking!&quot;">​</a></h1><h2 id="reference-links" tabindex="-1">Reference links <a class="header-anchor" href="#reference-links" aria-label="Permalink to &quot;Reference links&quot;">​</a></h2><ul><li>__<a href="https://github.com/trimstray/nginx-admins-handbook__" target="_blank" rel="noreferrer">https://github.com/trimstray/nginx-admins-handbook__</a></li><li>__<a href="https://github.com/GrrrDog/weird_proxies/wiki/nginx__" target="_blank" rel="noreferrer">https://github.com/GrrrDog/weird_proxies/wiki/nginx__</a></li><li>__<a href="https://github.com/h5bp/server-configs-nginx__" target="_blank" rel="noreferrer">https://github.com/h5bp/server-configs-nginx__</a></li><li>__<a href="https://github.com/leandromoreira/linux-network-performance-parameters__" target="_blank" rel="noreferrer">https://github.com/leandromoreira/linux-network-performance-parameters__</a></li><li><a href="https://github.com/nginx-boilerplate/nginx-boilerplate" target="_blank" rel="noreferrer">https://github.com/nginx-boilerplate/nginx-boilerplate</a></li><li><a href="https://www.nginx.com/blog/thread-pools-boost-performance-9x/" target="_blank" rel="noreferrer">https://www.nginx.com/blog/thread-pools-boost-performance-9x/</a></li><li><a href="https://www.nginx.com/blog/socket-sharding-nginx-release-1-9-1/" target="_blank" rel="noreferrer">https://www.nginx.com/blog/socket-sharding-nginx-release-1-9-1/</a></li><li><a href="https://www.nginx.com/blog/nginx-1-13-9-http2-server-push/" target="_blank" rel="noreferrer">https://www.nginx.com/blog/nginx-1-13-9-http2-server-push/</a></li><li><a href="https://www.nginx.com/blog/performing-a-b-testing-nginx-plus/" target="_blank" rel="noreferrer">https://www.nginx.com/blog/performing-a-b-testing-nginx-plus/</a></li><li><a href="https://www.nginx.com/blog/10-tips-for-10x-application-performance/" target="_blank" rel="noreferrer">https://www.nginx.com/blog/10-tips-for-10x-application-performance/</a></li><li><a href="https://www.nginx.com/blog/http-keepalives-and-web-performance/" target="_blank" rel="noreferrer">https://www.nginx.com/blog/http-keepalives-and-web-performance/</a></li><li><a href="https://www.nginx.com/blog/overcoming-ephemeral-port-exhaustion-nginx-plus/" target="_blank" rel="noreferrer">https://www.nginx.com/blog/overcoming-ephemeral-port-exhaustion-nginx-plus/</a></li><li><a href="https://www.nginx.com/blog/tcp-load-balancing-udp-load-balancing-nginx-tips-tricks/" target="_blank" rel="noreferrer">https://www.nginx.com/blog/tcp-load-balancing-udp-load-balancing-nginx-tips-tricks/</a></li><li><a href="https://www.nginx.com/blog/introducing-cicd-with-nginx-and-nginx-plus/" target="_blank" rel="noreferrer">https://www.nginx.com/blog/introducing-cicd-with-nginx-and-nginx-plus/</a></li><li><a href="https://www.nginx.com/blog/testing-the-performance-of-nginx-and-nginx-plus-web-servers/" target="_blank" rel="noreferrer">https://www.nginx.com/blog/testing-the-performance-of-nginx-and-nginx-plus-web-servers/</a></li><li><a href="https://www.nginx.com/blog/smart-efficient-byte-range-caching-nginx/" target="_blank" rel="noreferrer">https://www.nginx.com/blog/smart-efficient-byte-range-caching-nginx/</a></li><li><a href="https://www.nginx.com/blog/nginx-high-performance-caching/" target="_blank" rel="noreferrer">https://www.nginx.com/blog/nginx-high-performance-caching/</a></li><li><a href="https://www.nginx.com/resources/wiki/start/topics/examples/x-accel/" target="_blank" rel="noreferrer">https://www.nginx.com/resources/wiki/start/topics/examples/x-accel/</a></li><li><a href="https://nginx.org/r/pcre_jit" target="_blank" rel="noreferrer">https://nginx.org/r/pcre_jit</a></li><li><a href="https://nginx.org/r/ssl_engine" target="_blank" rel="noreferrer">https://nginx.org/r/ssl_engine</a> (<code>openssl engine -t </code>)</li><li><a href="https://www.nginx.com/blog/mitigating-ddos-attacks-with-nginx-and-nginx-plus/" target="_blank" rel="noreferrer">https://www.nginx.com/blog/mitigating-ddos-attacks-with-nginx-and-nginx-plus/</a></li><li><a href="https://www.nginx.com/blog/tuning-nginx/" target="_blank" rel="noreferrer">https://www.nginx.com/blog/tuning-nginx/</a></li><li><a href="https://github.com/intel/asynch_mode_nginx" target="_blank" rel="noreferrer">https://github.com/intel/asynch_mode_nginx</a></li><li><a href="https://openresty.org/download/agentzh-nginx-tutorials-en.html" target="_blank" rel="noreferrer">https://openresty.org/download/agentzh-nginx-tutorials-en.html</a></li><li><a href="https://www.maxcdn.com/blog/nginx-application-performance-optimization/" target="_blank" rel="noreferrer">https://www.maxcdn.com/blog/nginx-application-performance-optimization/</a></li><li><a href="https://www.nginx.com/blog/nginx-se-linux-changes-upgrading-rhel-6-6/" target="_blank" rel="noreferrer">https://www.nginx.com/blog/nginx-se-linux-changes-upgrading-rhel-6-6/</a></li><li><a href="https://medium.freecodecamp.org/a8afdbfde64d" target="_blank" rel="noreferrer">https://medium.freecodecamp.org/a8afdbfde64d</a></li><li><a href="https://medium.freecodecamp.org/secure-your-web-application-with-these-http-headers-fd66e0367628" target="_blank" rel="noreferrer">https://medium.freecodecamp.org/secure-your-web-application-with-these-http-headers-fd66e0367628</a></li><li><a href="https://gist.github.com/CMCDragonkai/6bfade6431e9ffb7fe88" target="_blank" rel="noreferrer">https://gist.github.com/CMCDragonkai/6bfade6431e9ffb7fe88</a></li><li><a href="https://gist.github.com/denji/9130d1c95e350c58bc50e4b3a9e29bf4" target="_blank" rel="noreferrer">https://gist.github.com/denji/9130d1c95e350c58bc50e4b3a9e29bf4</a></li><li><a href="https://8gwifi.org/docs/nginx-secure.jsp" target="_blank" rel="noreferrer">https://8gwifi.org/docs/nginx-secure.jsp</a></li><li><a href="http://www.codestance.com/tutorials-archive/nginx-tuning-for-best-performance-255" target="_blank" rel="noreferrer">http://www.codestance.com/tutorials-archive/nginx-tuning-for-best-performance-255</a></li><li><a href="https://ospi.fi/blog/centos-7-raise-nofile-limit-for-nginx.html" target="_blank" rel="noreferrer">https://ospi.fi/blog/centos-7-raise-nofile-limit-for-nginx.html</a></li><li><a href="https://www.linode.com/docs/websites/nginx/configure-nginx-for-optimized-performance" target="_blank" rel="noreferrer">https://www.linode.com/docs/websites/nginx/configure-nginx-for-optimized-performance</a></li><li><a href="https://haydenjames.io/nginx-tuning-tips-tls-ssl-https-ttfb-latency/" target="_blank" rel="noreferrer">https://haydenjames.io/nginx-tuning-tips-tls-ssl-https-ttfb-latency/</a></li><li><a href="https://gist.github.com/kekru/c09dbab5e78bf76402966b13fa72b9d2" target="_blank" rel="noreferrer">https://gist.github.com/kekru/c09dbab5e78bf76402966b13fa72b9d2</a></li></ul><h2 id="static-analyzers" tabindex="-1">Static analyzers <a class="header-anchor" href="#static-analyzers" aria-label="Permalink to &quot;Static analyzers&quot;">​</a></h2><ul><li><a href="https://github.com/yandex/gixy" target="_blank" rel="noreferrer">https://github.com/yandex/gixy</a></li></ul><h2 id="syntax-highlighting" tabindex="-1">Syntax highlighting <a class="header-anchor" href="#syntax-highlighting" aria-label="Permalink to &quot;Syntax highlighting&quot;">​</a></h2><ul><li><a href="https://github.com/chr4/sslsecure.vim" target="_blank" rel="noreferrer">https://github.com/chr4/sslsecure.vim</a></li><li><a href="https://github.com/chr4/nginx.vim" target="_blank" rel="noreferrer">https://github.com/chr4/nginx.vim</a></li><li><a href="https://github.com/nginx/nginx/tree/master/contrib/vim" target="_blank" rel="noreferrer">https://github.com/nginx/nginx/tree/master/contrib/vim</a></li></ul><h2 id="nginx-config-formatter" tabindex="-1">NGINX config formatter <a class="header-anchor" href="#nginx-config-formatter" aria-label="Permalink to &quot;NGINX config formatter&quot;">​</a></h2><ul><li><a href="https://github.com/rwx------/nginxConfigFormatterGo" target="_blank" rel="noreferrer">https://github.com/rwx------/nginxConfigFormatterGo</a></li><li><a href="https://github.com/1connect/nginx-config-formatter" target="_blank" rel="noreferrer">https://github.com/1connect/nginx-config-formatter</a></li><li><a href="https://github.com/lovette/nginx-tools/tree/master/nginx-minify-conf" target="_blank" rel="noreferrer">https://github.com/lovette/nginx-tools/tree/master/nginx-minify-conf</a></li></ul><h2 id="nginx-configuration-tools" tabindex="-1">NGINX configuration tools <a class="header-anchor" href="#nginx-configuration-tools" aria-label="Permalink to &quot;NGINX configuration tools&quot;">​</a></h2><ul><li><a href="https://github.com/nginxinc/crossplane" target="_blank" rel="noreferrer">https://github.com/nginxinc/crossplane</a></li><li><a href="https://github.com/valentinxxx/nginxconfig.io" target="_blank" rel="noreferrer">https://github.com/valentinxxx/nginxconfig.io</a></li></ul><h2 id="bbr-linux-4-9" tabindex="-1">BBR (Linux 4.9+) <a class="header-anchor" href="#bbr-linux-4-9" aria-label="Permalink to &quot;BBR (Linux 4.9+)&quot;">​</a></h2><ul><li><a href="https://blog.cloudflare.com/http-2-prioritization-with-nginx/" target="_blank" rel="noreferrer">https://blog.cloudflare.com/http-2-prioritization-with-nginx/</a></li><li>Linux v4.13+ as no longer required FQ (<code>q_disc</code>) with BBR.</li><li><a href="https://github.com/google/bbr/blob/master/Documentation/bbr-quick-start.md" target="_blank" rel="noreferrer">https://github.com/google/bbr/blob/master/Documentation/bbr-quick-start.md</a></li><li><a href="https://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next.git/commit/?id=218af599fa635b107cfe10acf3249c4dfe5e4123" target="_blank" rel="noreferrer">https://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next.git/commit/?id=218af599fa635b107cfe10acf3249c4dfe5e4123</a></li><li><a href="https://github.com/systemd/systemd/issues/9725#issuecomment-413369212" target="_blank" rel="noreferrer">https://github.com/systemd/systemd/issues/9725#issuecomment-413369212</a></li><li>If the latest Linux kernel distribution does not have <code>tcp_bbr</code> enabled by default:</li></ul><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#B392F0;">modprobe</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">tcp_bbr</span><span style="color:#E1E4E8;"> &amp;&amp; </span><span style="color:#79B8FF;">echo</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">&#39;tcp_bbr&#39;</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">&gt;&gt;</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">/etc/modules-load.d/bbr.conf</span></span>
<span class="line"><span style="color:#79B8FF;">echo</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">&#39;net.ipv4.tcp_congestion_control=bbr&#39;</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">&gt;&gt;</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">/etc/sysctl.d/99-bbr.conf</span></span>
<span class="line"><span style="color:#6A737D;"># Recommended for production, but with  Linux v4.13rc1+ can be used not only in FQ (\`q_disc&#39;) in BBR mode.</span></span>
<span class="line"><span style="color:#79B8FF;">echo</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">&#39;net.core.default_qdisc=fq&#39;</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">&gt;&gt;</span><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">/etc/sysctl.d/99-bbr.conf</span></span>
<span class="line"><span style="color:#B392F0;">sysctl</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">--system</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#6F42C1;">modprobe</span><span style="color:#24292E;"> </span><span style="color:#032F62;">tcp_bbr</span><span style="color:#24292E;"> &amp;&amp; </span><span style="color:#005CC5;">echo</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&#39;tcp_bbr&#39;</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">&gt;&gt;</span><span style="color:#24292E;"> </span><span style="color:#032F62;">/etc/modules-load.d/bbr.conf</span></span>
<span class="line"><span style="color:#005CC5;">echo</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&#39;net.ipv4.tcp_congestion_control=bbr&#39;</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">&gt;&gt;</span><span style="color:#24292E;"> </span><span style="color:#032F62;">/etc/sysctl.d/99-bbr.conf</span></span>
<span class="line"><span style="color:#6A737D;"># Recommended for production, but with  Linux v4.13rc1+ can be used not only in FQ (\`q_disc&#39;) in BBR mode.</span></span>
<span class="line"><span style="color:#005CC5;">echo</span><span style="color:#24292E;"> </span><span style="color:#032F62;">&#39;net.core.default_qdisc=fq&#39;</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">&gt;&gt;</span><span style="color:#24292E;"> </span><span style="color:#032F62;">/etc/sysctl.d/99-bbr.conf</span></span>
<span class="line"><span style="color:#6F42C1;">sysctl</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">--system</span></span></code></pre></div>`,61),t=[o];function p(r,i,c,y,h,d){return n(),a("div",null,t)}const E=s(l,[["render",p]]);export{m as __pageData,E as default};
