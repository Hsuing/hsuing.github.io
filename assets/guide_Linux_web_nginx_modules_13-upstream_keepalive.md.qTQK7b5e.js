import{_ as e,o as s,c as n,R as a}from"./chunks/framework.zUbWieqp.js";const p="/assets/upstream.GWoekCi1.jpg",l="/assets/3.Zea68kRs.png",y=JSON.parse('{"title":"","description":"","frontmatter":{},"headers":[],"relativePath":"guide/Linux/web/nginx/modules/13-upstream_keepalive.md","filePath":"guide/Linux/web/nginx/modules/13-upstream_keepalive.md","lastUpdated":1701684699000}'),t={name:"guide/Linux/web/nginx/modules/13-upstream_keepalive.md"},o=a(`<h2 id="_1-长连接服务" tabindex="-1">1.长连接服务 <a class="header-anchor" href="#_1-长连接服务" aria-label="Permalink to &quot;1.长连接服务&quot;">​</a></h2><p>nginx连接后端服务时，使用upstream的方式，并且设置keepalive可以建立长连接，减少创建连接的消耗，提升效率。</p><p>但是，nginx默认采用http1.0协议，如果后端没有返回Connection：keepalive的header，设置的长连接是不生效的，大并发下会出现大量time_wait的连接</p><p>两种解决方案：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#e1e4e8;">1、后台服务在response header中加Connetion：keepalive</span></span>
<span class="line"><span style="color:#e1e4e8;">2、在nginx配置中显示指明http1.1协议（默认长连接），并且设置header Connnction=&quot;&quot;</span></span>
<span class="line"><span style="color:#e1e4e8;"> </span></span>
<span class="line"><span style="color:#e1e4e8;">location ~ /XXX {</span></span>
<span class="line"><span style="color:#e1e4e8;">....</span></span>
<span class="line"><span style="color:#e1e4e8;">proxy_http_version 1.1;</span></span>
<span class="line"><span style="color:#e1e4e8;">proxy_set_header Connection &quot;&quot;;</span></span>
<span class="line"><span style="color:#e1e4e8;">}</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">1、后台服务在response header中加Connetion：keepalive</span></span>
<span class="line"><span style="color:#24292e;">2、在nginx配置中显示指明http1.1协议（默认长连接），并且设置header Connnction=&quot;&quot;</span></span>
<span class="line"><span style="color:#24292e;"> </span></span>
<span class="line"><span style="color:#24292e;">location ~ /XXX {</span></span>
<span class="line"><span style="color:#24292e;">....</span></span>
<span class="line"><span style="color:#24292e;">proxy_http_version 1.1;</span></span>
<span class="line"><span style="color:#24292e;">proxy_set_header Connection &quot;&quot;;</span></span>
<span class="line"><span style="color:#24292e;">}</span></span></code></pre></div><h3 id="应用场景" tabindex="-1">应用场景 <a class="header-anchor" href="#应用场景" aria-label="Permalink to &quot;应用场景&quot;">​</a></h3><p>nginx 通常情况下都是用来当作一个反向代理，通常一个请求都需要经过 ==client -&gt; nginx -&gt; backend_server 这么几成关系。通常情况下 client -&gt; nginx 使用的 HTTP 1.1 或者 2.0 的协议，keep-alive 复用了 TCP 的连接，减少了 TCP 频发创建和销毁带来的性能损失。但是默认情况下，nginx -&gt; backend_server 是 HTTP 1.0 的协议，并没有复用 TCP 的连接== <img src="`+p+`" alt=""></p><p>对发往上游请求当中要加上http头部图片里面的两条指令proxy_http_version和proxy_set_header，==因为http 1.0协议是不支持keepalive长连接的，为了防止用户发来的是http 1.0协议我们需要重置http_version为1.1，这样一直可以使用keepalive长连接。其次为了防止用户connection头部给我们传入的是closed而不是keepalived，我们需要主动设置向上游发的Connection值为Connection &quot;&quot;==</p><h3 id="语法" tabindex="-1">语法 <a class="header-anchor" href="#语法" aria-label="Permalink to &quot;语法&quot;">​</a></h3><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#e1e4e8;">Syntax: keepalive connections;</span></span>
<span class="line"><span style="color:#e1e4e8;">Default: —</span></span>
<span class="line"><span style="color:#e1e4e8;">Context: upstream</span></span>
<span class="line"><span style="color:#e1e4e8;"> </span></span>
<span class="line"><span style="color:#e1e4e8;">Syntax: keepalive_requests number;</span></span>
<span class="line"><span style="color:#e1e4e8;">Default: keepalive_requests 100;</span></span>
<span class="line"><span style="color:#e1e4e8;">Context: upstream</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">Syntax: keepalive connections;</span></span>
<span class="line"><span style="color:#24292e;">Default: —</span></span>
<span class="line"><span style="color:#24292e;">Context: upstream</span></span>
<span class="line"><span style="color:#24292e;"> </span></span>
<span class="line"><span style="color:#24292e;">Syntax: keepalive_requests number;</span></span>
<span class="line"><span style="color:#24292e;">Default: keepalive_requests 100;</span></span>
<span class="line"><span style="color:#24292e;">Context: upstream</span></span></code></pre></div><h2 id="_2-实现原理" tabindex="-1">2.实现原理 <a class="header-anchor" href="#_2-实现原理" aria-label="Permalink to &quot;2.实现原理&quot;">​</a></h2><p>首先每个进程需要一个connection pool，里面都是长连接，多进程之间是不需要共享这个连接池的。 一旦与后端服务器建立连接，则在当前请求连接结束之后不会立即关闭连接，而是把用完的连接保存在一个keepalive connection pool里面，以后每次需要建立向后连接的时候，只需要从这个连接池里面找，如果找到合适的连接的话，就可以直接来用这个连接，不需要重新创建socket或者发起connect()。这样既省下建立连接时在握手的时间消耗，又可以避免TCP连接的slow start。如果在keepalive连接池找不到合适的连接，那就按照原来的步骤重新建立连接。</p><p>如果你的连接池的数控制在128，总共线程池内的线程数是128 * nginx worker ，但因为你要应对更多的并发请求，所以临时又加了很多的连接，但这临时的连接是短连接和长连接要看你的nginx版本，我这1.8是长连接，那他如何被收回，两点保证，一点是他会主动去释放，另一点是keepalive timeout的时间</p><p><img src="`+l+`" alt=""></p><h2 id="_3-nginx长连接——keepalive" tabindex="-1">3.nginx长连接——keepalive <a class="header-anchor" href="#_3-nginx长连接——keepalive" aria-label="Permalink to &quot;3.nginx长连接——keepalive&quot;">​</a></h2><p>当使用nginx作为反向代理时，为了支持长连接，需要做到两点：</p><ul><li>从client到nginx的连接是长连接</li><li>从nginx到server的连接是长连接</li></ul><p>1、保持和client的长连接：</p><p>默认情况下，nginx已经自动开启了对client连接的keep alive支持（同时client发送的HTTP请求要求keep alive）。一般场景可以直接使用，但是对于一些比较特殊的场景，还是有必要调整个别参数（keepalive_timeout和keepalive_requests）</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#e1e4e8;">http {</span></span>
<span class="line"><span style="color:#e1e4e8;">    keepalive_timeout  120s 120s;</span></span>
<span class="line"><span style="color:#e1e4e8;">    keepalive_requests 10000;</span></span>
<span class="line"><span style="color:#e1e4e8;">}</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">http {</span></span>
<span class="line"><span style="color:#24292e;">    keepalive_timeout  120s 120s;</span></span>
<span class="line"><span style="color:#24292e;">    keepalive_requests 10000;</span></span>
<span class="line"><span style="color:#24292e;">}</span></span></code></pre></div><p>1）keepalive_timeout 语法:</p><p>keepalive_timeout timeout [header_timeout];</p><ol><li>第一个参数：设置keep-alive客户端连接在服务器端保持开启的超时值（默认75s）；值为0会禁用keep-alive客户端连接；</li><li>第二个参数：可选、在响应的header域中设置一个值“Keep-Alive: timeout=time”；通常可以不用设置；</li></ol><p>注：keepalive_timeout默认75s，一般情况下也够用，对于一些请求比较大的内部服务器通讯的场景，适当加大为120s或者300s；</p><p>2）keepalive_requests： ==keepalive_requests指令用于设置一个keep-alive连接上可以服务的请求的最大数量，当最大请求数量达到时，连接被关闭。默认是100==。这个参数的真实含义，是指一个keep alive建立之后，nginx就会为这个连接设置一个计数器，记录这个keep alive的长连接上已经接收并处理的客户端请求的数量。如果达到这个参数设置的最大值时，则nginx会强行关闭这个长连接，逼迫客户端不得不重新建立新的长连接。 大多数情况下当QPS(每秒请求数)不是很高时，默认值100凑合够用。但是，对于一些QPS比较高（比如超过10000QPS，甚至达到30000,50000甚至更高) 的场景，默认的100就显得太低。</p><p>简单计算一下，QPS=10000时，客户端每秒发送10000个请求(通常建立有多个长连接)，每个连接只能最多跑100次请求，意味着平均每秒钟就会有100个长连接因此被nginx关闭。同样意味着为了保持QPS，客户端不得不每秒中重新新建100个连接。因此，就会发现有大量的TIME_WAIT的socket连接(即使此时keep alive已经在client和nginx之间生效)。==因此对于QPS较高的场景，非常有必要加大这个参数，以避免出现大量连接被生成再抛弃的情况，减少TIME_WAIT==</p><p>2、保持和server的长连接： 为了让nginx和后端server（nginx称为upstream）之间保持长连接，典型设置如下：（默认nginx访问后端都是用的短连接(HTTP1.0)，一个请求来了，Nginx 新开一个端口和后端建立连接，后端执行完毕后主动关闭该链接）</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#e1e4e8;">  upstream  BACKEND {</span></span>
<span class="line"><span style="color:#e1e4e8;">        server   192.168.0.1：8080  weight=1 max_fails=2 fail_timeout=30s;</span></span>
<span class="line"><span style="color:#e1e4e8;">        server   192.168.0.2：8080  weight=1 max_fails=2 fail_timeout=30s;</span></span>
<span class="line"><span style="color:#e1e4e8;">        keepalive 10000;        // 这个很重要！</span></span>
<span class="line"><span style="color:#e1e4e8;">    }</span></span>
<span class="line"><span style="color:#e1e4e8;">server ｛</span></span>
<span class="line"><span style="color:#e1e4e8;">	location / {</span></span>
<span class="line"><span style="color:#e1e4e8;">		add_header Cache-Control no-store;</span></span>
<span class="line"><span style="color:#e1e4e8;">            add_header Pragma  no-cache;</span></span>
<span class="line"><span style="color:#e1e4e8;">            proxy_http_version 1.1;         // 这两个最好也设置</span></span>
<span class="line"><span style="color:#e1e4e8;">            proxy_set_header Connection &quot;&quot;;</span></span>
<span class="line"><span style="color:#e1e4e8;">	}</span></span>
<span class="line"><span style="color:#e1e4e8;">｝</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292e;">  upstream  BACKEND {</span></span>
<span class="line"><span style="color:#24292e;">        server   192.168.0.1：8080  weight=1 max_fails=2 fail_timeout=30s;</span></span>
<span class="line"><span style="color:#24292e;">        server   192.168.0.2：8080  weight=1 max_fails=2 fail_timeout=30s;</span></span>
<span class="line"><span style="color:#24292e;">        keepalive 10000;        // 这个很重要！</span></span>
<span class="line"><span style="color:#24292e;">    }</span></span>
<span class="line"><span style="color:#24292e;">server ｛</span></span>
<span class="line"><span style="color:#24292e;">	location / {</span></span>
<span class="line"><span style="color:#24292e;">		add_header Cache-Control no-store;</span></span>
<span class="line"><span style="color:#24292e;">            add_header Pragma  no-cache;</span></span>
<span class="line"><span style="color:#24292e;">            proxy_http_version 1.1;         // 这两个最好也设置</span></span>
<span class="line"><span style="color:#24292e;">            proxy_set_header Connection &quot;&quot;;</span></span>
<span class="line"><span style="color:#24292e;">	}</span></span>
<span class="line"><span style="color:#24292e;">｝</span></span></code></pre></div><p>upstream中的keepalive设置：</p><p>此处keepalive的含义不是开启、关闭长连接的开关；也不是用来设置超时的timeout；更不是设置长连接池最大连接数。官方解释：</p><ol><li>The connections parameter sets the maximum number of idle keepalive connections to upstream servers connections（设置到upstream服务器的空闲keepalive连接的最大数量）</li><li>When this number is exceeded, the least recently used connections are closed. （当这个数量被突破时，最近使用最少的连接将被关闭）</li><li>It should be particularly noted that the keepalive directive does not limit the total number of connections to upstream servers that an nginx worker process can open.（特别提醒：keepalive指令不会限制一个nginx worker进程到upstream服务器连接的总数量）</li></ol><p>总结： keepalive 这个参数一定要小心设置，尤其对于QPS比较高的场景，推荐先做一下估算，根据QPS和平均响应时间大体能计算出需要的长连接的数量。比如前面10000 QPS和100毫秒响应时间就可以推算出需要的长连接数量大概是1000. 然后将keepalive设置为这个长连接数量的10%到30%。比较懒的同学，可以直接设置为keepalive=1000之类的，一般都OK的了</p><p>3、综上，出现大量TIME_WAIT的情况 1）导致 nginx端出现大量TIME_WAIT的情况有两种：</p><ul><li>keepalive_requests设置比较小，高并发下超过此值后nginx会强制关闭和客户端保持的keepalive长连接；（主动关闭连接后导致nginx出现TIME_WAIT）</li><li>keepalive设置的比较小（空闲数太小），导致高并发下nginx会频繁出现连接数震荡（超过该值会关闭连接），不停的关闭、开启和后端server保持的keepalive长连接；</li></ul><p>2）导致后端server端出现大量TIME_WAIT的情况： nginx没有打开和后端的长连接，即：没有设置proxy_http_version 1.1;和proxy_set_header Connection “”;从而导致后端server每次关闭连接，高并发下就会出现server端出现大量TIME_WAIT</p>`,35),i=[o];function c(r,d,u,v,h,_){return s(),n("div",null,i)}const g=e(t,[["render",c]]);export{y as __pageData,g as default};
